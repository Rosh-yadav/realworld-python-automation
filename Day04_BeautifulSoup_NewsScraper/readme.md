
---

````markdown
# ğŸ“° Scraping Headlines From News Websites Using BeautifulSoup in Python

## ğŸ§  Big Picture: What This Script Does

Your goal:
ğŸ‘‰ â€œVisit a news website â†’ read the webpage â†’ pick out headline text â†’ print it.â€

So, our Python program does **4 main things**:

1. **Get** the webpageâ€™s HTML (using `requests`)
2. **Parse** the HTML (using `BeautifulSoup`)
3. **Find** all headline tags (like `<h2>` or `<h3>`)
4. **Extract** text and **print** the headlines

---

## ğŸ§© Letâ€™s Break Down the Code

### ğŸ§± 1. Importing Libraries

```python
import requests
from bs4 import BeautifulSoup
````

* **`requests`** â†’ lets Python visit web pages like a browser.
* **`BeautifulSoup`** â†’ helps Python read and understand the messy HTML code of a webpage.

---

### âš™ï¸ 2. Defining a Function

```python
def get_news_headlines(url):
    """
    Extracts news headlines from the provided news website URL.
    """
```

* `def` means we are defining a **function** â€” a reusable block of code.
* The function name is `get_news_headlines`, and it takes one input â€” the **URL** of the website we want to scrape.
* The triple quotes (`""" """`) define a **docstring** â€” a short description of what the function does.

Example usage:

```python
get_news_headlines("https://www.bbc.com/news")
```

---

### ğŸŒ 3. Sending a Request to the Website

```python
try:
    response = requests.get(url, timeout=10)
    response.raise_for_status()
except requests.exceptions.RequestException as e:
    print(f"âŒ Error fetching the URL: {e}")
    return []
```

* `requests.get(url)` â†’ sends a GET request (like opening the page in your browser).
* `response.text` â†’ contains the HTML content.
* `response.status_code` â†’ 200 means success, 404 means â€œnot found.â€
* `response.raise_for_status()` â†’ automatically throws an error for bad responses.
* `try...except` â†’ prevents your program from crashing if something goes wrong (like no internet or invalid URL).

---

### ğŸ§  4. Parsing the HTML

```python
soup = BeautifulSoup(response.text, 'lxml')
```

* Converts the HTML code into a **structured format** you can search.
* `'lxml'` is a fast and powerful parser that helps BeautifulSoup read HTML properly.

Example:

```python
soup.find_all('h2')
```

â†’ Finds all `<h2>` tags.

---

### ğŸ“° 5. Finding Headline Elements

```python
headline_elements = soup.find_all(['h2', 'h3'])
```

* `.find_all()` â†’ looks through the HTML and finds all tags matching your list.
* Here, weâ€™re finding all `<h2>` and `<h3>` tags.
* Most news sites (like BBC, CNN, etc.) use these tags for headlines.

---

### âœ‚ï¸ 6. Extracting Text from Each Tag

```python
headlines = []
for element in headline_elements:
    headline_text = element.get_text(strip=True)
    if headline_text and len(headline_text.split()) > 3:
        headlines.append(headline_text)
```

* Start with an empty list `headlines = []`.
* Loop through each element found in the HTML.
* `element.get_text(strip=True)` removes HTML tags and keeps clean text.
* The `if` condition ensures:

  * Itâ€™s not empty (`headline_text`)
  * It has more than 3 words (to skip short labels like â€œHomeâ€, â€œMenuâ€)
* Add valid headlines to the list using `.append()`.

---

### ğŸš« 7. Removing Duplicates

```python
return list(set(headlines))
```

* Some websites repeat headlines multiple times.
* `set()` removes duplicates.
* `list(set(...))` converts it back to a list before returning it.

---

### ğŸš€ 8. The Main Program

```python
if __name__ == "__main__":
    news_url = "https://www.bbc.com/news"
    headlines = get_news_headlines(news_url)
```

* This block runs only if you **execute** the file directly (not when imported).
* It passes the URL `"https://www.bbc.com/news"` to the function.

---

### ğŸ–¨ï¸ 9. Printing the Headlines

```python
if headlines:
    print(f"\nğŸ—ï¸ Headlines from {news_url}:\n")
    for i, headline in enumerate(headlines[:15], start=1):
        print(f"{i}. {headline}")
else:
    print("âš ï¸ No headlines found.")
```

* `if headlines:` checks if the list is not empty.
* `enumerate()` gives both index (`i`) and value (`headline`).
* `[:15]` limits output to the first 15 headlines.
* Nicely prints the results in a numbered list.

---

### ğŸ” Example Output

```
ğŸ—ï¸ Headlines from https://www.bbc.com/news:

1. World leaders gather for global climate summit
2. India launches new moon mission
3. Tech giants face new privacy laws
```

---

## ğŸ’¡ Notes

* Works best on **static** news sites (like BBC, Reuters, TechCrunch).
* **Dynamic sites** (like Zee News or Aaj Tak) load data using JavaScript, so BeautifulSoup wonâ€™t see the headlines.
* For those, youâ€™d need **Selenium** (a tool that automates a browser).

---

## âœ… Requirements

Install dependencies before running:

```bash
pip install requests beautifulsoup4 lxml
```

---

## ğŸ§‘â€ğŸ’» Run the Script

```bash
python scrapping.py
```

---

## ğŸ Output

Youâ€™ll see something like:

```
ğŸ—ï¸ Headlines from https://www.bbc.com/news:

1. BBC reporter wins international award
2. Global markets show early signs of recovery
3. SpaceX launches new Starlink satellites
```

---

> ğŸ‰ Congratulations â€” you just built your **first web scraping project** in Python using BeautifulSoup!
> Keep experimenting with other news sites and tags to learn more.

```

---


